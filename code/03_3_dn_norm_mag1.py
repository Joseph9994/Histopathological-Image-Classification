# -*- coding: utf-8 -*-
"""03.3_DN_NORM_MAG1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D8HQ3dCJB9BbfVdfHrg27Oy-maQMxzb0
"""

# INSTALLINGS

!pip install tensorflow==2.1.0
!pip install keras==2.3.1
!pip install segmentation_models==1.0.1
!pip install h5py==2.10.0
!pip install plotly==5.3.1
!pip install scikit-learn
!pip install imagecodecs

!nvidia-smi

!nvidia-smi

# LINKAGE TO GOOGLE DRIVE AND LIBRERIES IMPORTING

from google.colab import drive
drive.mount('/content/drive')

import os
import random
import numpy as np
import plotly.express as px
import imagecodecs

from matplotlib import pyplot as plt
from tqdm import tqdm
from skimage.io import imread, imshow, imsave
from skimage.transform import resize
from skimage.segmentation import mark_boundaries
from scipy import ndimage
from skimage.util import img_as_float,img_as_ubyte, crop
from skimage.morphology import binary_dilation
from sklearn.utils import shuffle

from keras.callbacks import ModelCheckpoint
from keras.callbacks import CSVLogger
from keras.callbacks import EarlyStopping
from keras.utils.np_utils import to_categorical
from keras.preprocessing.image import ImageDataGenerator
from keras.models import load_model

from segmentation_models import Unet

# DATASET UNRAR: LOADING DATASET IN COLAB

!pip install unrar
!unrar x "drive/MyDrive/cytology challenge condivisa/00_DATASET/train.rar"     # unraring training set
!unrar x "drive/MyDrive/cytology challenge condivisa/00_DATASET/validation.rar"   # unraring validation set
!unrar x "drive/MyDrive/cytology challenge condivisa/00_DATASET/test.rar"         # unraring test set

# LOAD PRE-PROCESSED TRAINING SET AND VALIDATION SET (READY TO USE) and SET UP NET'S SETTINGS

# load
images = np.load('drive/MyDrive/cytology challenge condivisa/01_PRE-PROCESSED/NORM_IL.npz')  # images loading <--------------------------------------- CHANGE HERE
labels = np.load('drive/MyDrive/cytology challenge condivisa/01_PRE-PROCESSED/IL1_manual_mask_512x512.npz')  # manual annotations loading <-------- CHANGE HERE
X_tr = images['X_tr']
X_vl = images['X_vl']
Y_tr = labels['Y_tr']
Y_vl = labels['Y_vl']
images.close()
labels.close()
del images,labels

# settings
current_net = 'DN_NORM_MAG1'  # name of the model that will be trained <-------------------------------------------------------------- CHANGE HERE
rsz = X_tr.shape[1]  # resizing size (resize images to rsz x rsz)
NUM_CLASSES = Y_tr.max() + 1 # number of classes choosen for the problem

# conversion of labels to categorical: to minimize required space for storage
# labels has been saved as greyscale images and not as categorical labels,
# conversion is done here
Y_tr = to_categorical(Y_tr, num_classes = NUM_CLASSES, dtype='float32')  # conversion to categorical data
Y_vl = to_categorical(Y_vl, num_classes = NUM_CLASSES, dtype='float32')  # conversion to categorical data

# #controllo nomi
# !unrar x "drive/MyDrive/cytology challenge condivisa/03_PREDICTED/DN_NORM_IL1.rar"
# ila = np.load('drive/MyDrive/cytology challenge condivisa/01_PRE-PROCESSED/NORM_IL.npz')  # images loading <--------------------------------------- CHANGE HERE
# masc_bu = np.load('drive/MyDrive/cytology challenge condivisa/01_PRE-PROCESSED/PRA_manual_mask_512x512.npz')  # manual annotations loading <-------- CHANGE HERE
# bu = np.load('drive/MyDrive/cytology challenge condivisa/01_PRE-PROCESSED/PRA1.npz')  # images loading <--------------------------------------- CHANGE HERE

# GESU = sorted(os.listdir('DN_NORM_IL1/train/prob_map'))
# print(GESU)

# CREATING DIRECTORIES IN WHICH TO STORE THE PREDICTED PROBABILITY MAPS

# prediction directories
if not os.path.exists(current_net):
  os.mkdir(current_net)

if not os.path.exists(current_net + "/train"):
  os.mkdir(current_net + "/train")

if not os.path.exists(current_net + "/validation"):
  os.mkdir(current_net + "/validation")

if not os.path.exists(current_net + "/test"):
  os.mkdir(current_net + "/test")



# probability maps directories
path_predicted_tr_pm = os.path.join(current_net,"train","prob_map")
if not os.path.exists(path_predicted_tr_pm):
  os.mkdir(path_predicted_tr_pm)

path_predicted_vl_pm = os.path.join(current_net,"validation","prob_map")
if not os.path.exists(path_predicted_vl_pm):
  os.mkdir(path_predicted_vl_pm)

path_predicted_ts_pm = os.path.join(current_net,"test","prob_map")
if not os.path.exists(path_predicted_ts_pm):
  os.mkdir(path_predicted_ts_pm)

# # DATA AUGMENTATION SETTINGS

# # def coloraug(image):

# #       if image.dtype == 'float32':
# #         image = image
# #       elif image.dtype == 'uint8':
# #         image = np.array(image)
# #         #image = tf.image.random_hue(image,0.2)
# #         #image = tf.image.random_saturation(image,0.5,1.5)
# #         image = tf.image.random_contrast(image,0.8,1.2)
# #         image = image.numpy()
# #       return image


# # training set
# image_datagen = ImageDataGenerator(
#                                   # rotation_range = 180,
#                                   horizontal_flip = True,
#                                   vertical_flip = True,
#                                   fill_mode = 'constant',
#                                   cval = 0,
#                                   zoom_range = [0.7,1.3],
#                                   brightness_range=[0.8,1.2],
#                                   #preprocessing_function = coloraug
# )


# # validation set
# val_datagen = ImageDataGenerator()

# # Generator function
# def XYaugmentGenerator(X1, y, batch_sz, sd):
#         genX1 = image_datagen.flow(X1, y, batch_size=batch_sz,seed = sd)
#         genX2 = image_datagen.flow(y, X1, batch_size=batch_sz, seed = sd)
#         while True:
#             X1i = genX1.next()  #The next() function returns the next item in an iterator.
#             X2i = genX2.next()
#             yield X1i[0], X2i[0]

# # NET TRAINING

# # defining U-NET architecture
# BACKBONE = 'densenet201'
# model = Unet(backbone_name = BACKBONE,
#             input_shape = (rsz,rsz,3),
#             encoder_weights = 'imagenet',
#             encoder_freeze = True,
#             decoder_block_type = 'transpose',
#             classes = NUM_CLASSES,
#             activation = 'softmax')

# # defining optimization algorithm and loss function
# model.compile('Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])

# # training and parameters <---------------------------------------------------------------------- CHANGE HERE (below)
# n_epochs = 20
# batch_sz = 2
# sd=1
# monitor_value = 'val_categorical_accuracy'
# verbose_value = 1
# min_delta_value = 0.001
# patience_value = 10
# mode_value = 'max'

# # checkpoint definition
# csv_logger = CSVLogger('./log.out', append=True, separator=';')
# earlystopping = EarlyStopping(monitor = monitor_value, verbose = verbose_value, min_delta = min_delta_value, patience = patience_value, mode = mode_value, restore_best_weights = True)
# callbacks_list = [csv_logger, earlystopping]


# # model training
# results = model.fit_generator(XYaugmentGenerator(X_tr,Y_tr, batch_sz, sd),
#                               steps_per_epoch = np.ceil(float(len(X_tr))/float(batch_sz)),
#                               validation_data = val_datagen.flow(X_vl,Y_vl,batch_sz),
#                               validation_steps = np.ceil(float(len(X_vl))/float(batch_sz)),
#                               shuffle = True,
#                               epochs = n_epochs,
#                               callbacks = callbacks_list)

# SAVE/LOAD OF TRAINED MODEL

if not os.path.exists('drive/MyDrive/cytology challenge condivisa/02_TRAINED MODELS/'):
    os.mkdir('drive/MyDrive/cytology challenge condivisa/02_TRAINED MODELS/')

#model.save('drive/MyDrive/cytology challenge condivisa/02_TRAINED MODELS/' + current_net)
model = load_model('drive/MyDrive/cytology challenge condivisa/02_TRAINED MODELS/' + current_net)

# PROBABILITY MAP PREDICTIONS ON TRAINING SET

# path
tr_IMGS_path = os.path.join('train','images')

# cycling on all images to apply the U-NET
tr_images = sorted(os.listdir(tr_IMGS_path))

for n,id_ in tqdm(enumerate(tr_images), total=len(tr_images)):

    img = np.reshape(img_as_ubyte(X_tr[n]),(1,rsz,rsz,3))  # load and resizing (and resahping to feed for net format) of stained image
    softmax = model.predict(img)  # apply CNN for prediction

    imsave(os.path.join(path_predicted_tr_pm,id_),softmax)  # predicted heatmap saving

# PROBABILITY MAP PREDICTIONS ON VALIDATION SET

# Path
vl_IMGS_path = os.path.join('validation','images')

# cycling on all images to apply the U-NET
vl_images = sorted(os.listdir(vl_IMGS_path))

for n, id_ in tqdm(enumerate(vl_images), total=len(vl_images)):

    img = np.reshape(img_as_ubyte(X_vl[n]),(1,rsz,rsz,3))  # load and resizing (and resahping to feed for net format) of stained image
    softmax = model.predict(img)  # apply CNN for prediction

    imsave(os.path.join(path_predicted_vl_pm,id_),softmax)  # predicted heatmap saving

# SUL TEST DEVO APPLICARE LO STESSO PRE-PROCESSING PRIMA
# # PROBABILITY MAP PREDICTIONS ON TEST SET

# # Path
# ts_IMGS_path = os.path.join('test','images')

# # cycling on all images to apply the U-NET
# ts_images = os.listdir(ts_IMGS_path)
# for n, id_ in tqdm(enumerate(ts_images), total=len(ts_images)):

#     img = np.reshape(img_as_ubyte(resize(imread(ts_IMGS_path+'/'+id_),(rsz,rsz))),(1,rsz,rsz,3))  # load and resizing (and resahping to feed for net format) of stained image
#     softmax = model.predict(img)  # apply CNN for prediction

#     imsave(os.path.join(path_predicted_ts_pm,id_),softmax)  # predicted heatmap saving

#SALVATAGGIO RISULTATI COMPRESSI COME .rar DA COLAB A DRIVE

#compressione
!apt-get install rar  # installing necessary library
!rar a "DN_NORM_MAG1" "DN_NORM_MAG1" # <------------------------------------------------------------------------- CHANGE HERE

#copia da colab a drive (cartella "03_PREDICTED" in "cytology challenge")

import shutil
shutil.copyfile(current_net + ".rar", "/content/drive/MyDrive/cytology challenge condivisa/03_PREDICTED/" + current_net + ".rar")