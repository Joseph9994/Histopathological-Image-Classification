# -*- coding: utf-8 -*-
"""prova_cytology1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17pADgRoPhSEUNCkSvDW7aUdkga-REfRW

Installazione librerie
"""

# Install libriary dependencies for running deep learning
!pip install tensorflow==2.1.0
!pip install keras==2.3.1
!pip install segmentation_models==1.0.1
!pip install h5py==2.10.0

# install imagecodecs for reading masks
!pip install imagecodecs
import imagecodecs

# colab access + import libraries
from google.colab import drive
drive.mount('/content/drive')

import os
import random
import numpy as np
import plotly.express as px
import cv2

from matplotlib import pyplot as plt
from tqdm import tqdm
from skimage.io import imread, imshow, imsave

from skimage.transform import resize
from skimage import img_as_ubyte

from keras.callbacks import ModelCheckpoint
from keras.callbacks import CSVLogger
from keras.callbacks import EarlyStopping
from keras.utils.np_utils import to_categorical
from keras.preprocessing.image import ImageDataGenerator
from keras.models import load_model

from segmentation_models import Unet

# Caricamento dataset in formato .rar da Google Drive a Colab
!pip install unrar
!unrar x "/content/drive/MyDrive/eim/cytology/train.rar"     # unraring training set
!unrar x "/content/drive/MyDrive/eim/cytology/validation.rar"   # unraring validation set
!unrar x "/content/drive/MyDrive/eim/cytology/test.rar"         # unraring test set

"""inizializzazione path + visualizzazione di una immagine random"""

# Si vuole allenare una rete che prenda in ingresso un'immagine 512x512x3 (rgb)
# e la rispettiva maschera di segmentazione (0:background, 255:lesione)
IMG_WIDTH = 512
IMG_HEIGHT = 512
IMG_CHANNELS = 3
NUM_CLASSES = 2

# Path
tr_IMGS_path = os.path.join('train','images')
tr_MANU_path = os.path.join('train','manual')
val_IMGS_path = os.path.join('validation', 'images')
val_MANU_path = os.path.join('validation', 'manual')

# Extracting list of images
tr_images = os.listdir(tr_IMGS_path)
val_images = os.listdir(val_IMGS_path)
print(f"there are {len(tr_images)} images in the training set")
print(f"there are {len(val_images)} images in the validation set")
print(f"train_images: {tr_images}\nval_images:{val_images}")

#estrazione causale immagine
rand_index=np.random.choice(len(tr_images))
print(f"random image: {tr_images[rand_index]})")

I = imread(os.path.join(tr_IMGS_path, tr_images[rand_index]))
mask = imagecodecs.imread(os.path.join(tr_MANU_path, tr_images[rand_index]))
print(f"mask shape: {mask.shape}")
if len(mask.shape)>2:                                 # if there is more than 1 MM cell in the current image
    mask = np.sum(mask,2,np.uint8)                    # merge the N layers segmentation in a unique greyscale image

# image + mask visualization
fig=plt.figure(figsize=(30,10))
ax1=plt.subplot(1,2,1)
ax1.imshow(I)
ax1.set_title('original image')

ax2=plt.subplot(1,2,2)
ax2.imshow(mask, cmap=plt.cm.gray)
ax1.set_title('mask')

"""***
***training senza preprocessing***

preparazione dataset
"""

print(len(tr_images))
dimensions=(len(tr_images),IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)
print(dimensions)

from genericpath import exists
# Creazione di una matrice 4D [#immagini, altezza, larghezza, #canali] che conterrà
# tutte le immagini di training (X_train) mentre tutte le corrispettive maschere
# di segmentazione saranno all'interno della matrice Y_train. Ragionamento analogo
# per il validation set (X_val,Y_val)
dimensions=(len(tr_images),IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)
mask_dimensions=(len(tr_images),IMG_HEIGHT,IMG_WIDTH,NUM_CLASSES)

# NUM_CLASSES is needed by the moment that we use "to_categorical"
# transformation (so the masks to give as input to the
# net will have 2 layers, 1 in which starting mask ones are ones
# and another in which starting mask zeros are ones)

# Inizializzazioni matrici NB: le immagini devono essere in formato uint8 mentre le maschere BW in float32
X_train = np.zeros(dimensions, dtype=np.uint8)
Y_train = np.zeros(mask_dimensions, dtype=np.float32)


for n, id_ in tqdm(enumerate(tr_images), total=len(tr_images)):

    # la variabile "n" rappresenta un contatore (0-num_immagini) mentre "id_"
    # contiene il nome della n-esima immagine

    # Lettura immagine e ricampionamento a 512x512
    fn= os.path.join(tr_IMGS_path, id_)
    img = imread(fn)
    img = resize(img, [IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS])
    img = img_as_ubyte(img) #this is needed by the moment that resize convert image in float64 format (so in range 0,1) and we are going to insert
                                    #this converted image in an uint8 array, this leading to have an image in uint8 with only zeros and ones (it would appear
                                    #black... AND IT IS A WRONG IMAGE)... an ALMOST equivalent implementation would be just setting "preserve_range" parameter
                                    #on True in skimage.resize function
    X_train[n] = img

    # Lettura maschera BW e ricampionamento maschera a 512x512
    fn1=os.path.join(tr_MANU_path, id_)
    mask = imagecodecs.imread(fn1)
    print(f"mask shape: {mask.shape}")
    dim=mask.shape
    print(dim)
    if len(dim)>2:
      if mask.shape[2]>=1:
         mask = np.sum(mask,2,np.uint8)                     # merge the N layers segmentation in a unique greyscale image

    mask = resize(mask, [IMG_HEIGHT,IMG_WIDTH], preserve_range=True)
    """
    equivalent way:
    mask = resize(mask,[IMG_HEIGHT,IMG_WIDTH], preserve_range=True) #here i did it the other way... that in this kind won't affect the results in a bay way w/
           anzichè preserved_range                                  #respect to use "skimage.img_as_ubyte" by the moment that under values near to 255 will be
           mettere [IMG_HEIGHT,IMG_WIDTH]                           #set to 1 and values near to 0 will be set to 0 and little changes as said wont't make any
                                                                  #difference given the threshold of 127 (contest:notice that the masks originally were in uint8
                                                                  #data format w/ NOT SEGMENTED set to 0 and SEGMENTED set to 255)
    """
    mask[mask<127] = 0
    mask[mask>=127] = 1

    # Conversione della maschera in dato categorico
    mask = to_categorical(mask, num_classes=NUM_CLASSES, dtype='float32') #I think this makes a category for each possible value/level (prof said this is
                                                                          #needed to use the keras DL framework[i.e. it is implemented to perform well on
                                                                          #masks in this datatype] --> this due to the fact that open sources Python library
                                                                          #being open sources are implemented for general purpose and not specificly for
                                                                          #medical purpose, so in general purpose world problem classes may be easily bigger
                                                                          #than 2 and for this reason a layer for each class is needed... this also explains
                                                                          #why data format of mask is needed to be float32 for the implementation: considering
                                                                          #general purpose problems in which classes can also be bigger than 256 a float32
                                                                          #codification is required) in the pixels of the image (in our case).
                                                                          #
                                                                          #Also parameter "dtype" set to float32 is quite useless btm that this is done by
                                                                          #default.
    Y_train[n] = mask

# Creazione matrici per validation set
dimensions=(len(val_images),IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)
mask_dimensions=(len(val_images),IMG_HEIGHT,IMG_WIDTH,NUM_CLASSES)
# Inizializzazioni matrici
X_val = np.zeros(dimensions, dtype=np.uint8)
Y_val = np.zeros(mask_dimensions, dtype=np.float32)

for n, id_ in tqdm(enumerate(val_images), total=len(val_images)):
    # Lettura immagine e ricampionamento a 512x512
    fn=os.path.join(val_IMGS_path, id_)
    img = imread(fn)
    img = resize(img, [IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS])
    img = img_as_ubyte(img)
    X_val[n] = img

    # Lettura maschera BW e ricampionamento maschera a 512x512
    fn1=os.path.join(val_MANU_path, id_)
    mask = imagecodecs.imread(fn1)
    print(f"mask shape: {mask.shape}")
    dim=mask.shape
    print(dim)
    if len(dim)>2:
      if mask.shape[2]>=1:
         mask = np.sum(mask,2,np.uint8)                     # merge the N layers segmentation in a unique greyscale image

    mask = resize(mask, [IMG_HEIGHT,IMG_WIDTH], preserve_range=True)

    mask[mask<127] = 0
    mask[mask>=127] = 1

    # Conversione della maschera in dato categorico
    mask = to_categorical(mask, num_classes=NUM_CLASSES, dtype='float32')
    Y_val[n] = mask

"""verifica caricamento dati"""

# Estrazione di una casuale immagine di training
from random import randint

random_index = randint(0,len(tr_images)-1)
print(random_index)

figure=imread(tr_IMGS_path+'/'+tr_images[random_index])     #immagine presa a caso
resized_fig=X_train[random_index]                                #stessa immagine, resized
mask_fig=imagecodecs.imread(tr_MANU_path+'/'+tr_images[random_index])  #relativa maschera
print(mask_fig.shape)
if len(mask_fig.shape)>2:                                 # if there is more than 1 MM cell in the current image
    mask_fig = np.sum(mask_fig,2,np.uint8)                    # merge the N layers segmentation in a unique greyscale image
resized_mask=resize(mask_fig, [IMG_HEIGHT,IMG_WIDTH], preserve_range=True)
#resized_mask=Y_train[random_index,:,:,1]                         #bisogna mettere [random_index,:,:,1] perchè altrimenti
                                                                 #prende tutta la tupla Y_train[(indice, 512, 512, 2)]
                                                                 #con 2= canali che non possono essere plottati insieme
                                                                 #sceglo 1 perchè cosi mi plotta sfondo nero e oggetto bianco

print(resized_mask.shape)

#plot image
f1 = plt.figure(figsize=(10, 5))
ax1 = plt.subplot(1, 2, 1)
pos1 = ax1.imshow(figure)
ax1.axis('off')
ax1.set_title("img pre resize")

ax2 = plt.subplot(1, 2, 2)
pos2 = ax2.imshow(resized_fig)
ax2.axis('off')
ax2.set_title("img post resize")

#plot mask
f2 = plt.figure(figsize=(10, 5))
ax1 = plt.subplot(1, 2, 1)
pos1 = ax1.imshow(mask_fig, cmap=plt.cm.gray)
ax1.axis('off')
ax1.set_title("mask pre resize")

ax2 = plt.subplot(1, 2, 2)
pos2 = ax2.imshow(resized_mask, cmap=plt.cm.gray)
ax2.axis('off')
ax2.set_title("mask post resize")

"""Data augmentation"""

# Data augmentation (training set)
image_datagen = ImageDataGenerator(rotation_range = 180,
                                   width_shift_range = 0.2,
                                   height_shift_range = 0.2,
                                   horizontal_flip = True,
                                   vertical_flip = True,
                                   fill_mode = 'reflect')

# Data augmentation (validation set)
val_datagen = ImageDataGenerator()

# Generator (NON TOCCARE LE RIGHE SOTTOSTANTI)
seed = 1
def XYaugmentGenerator(X1, y, seed, batch_size):
    genX1 = image_datagen.flow(X1, y, batch_size=batch_size, seed=seed)
    genX2 = image_datagen.flow(y, X1, batch_size=batch_size, seed=seed)
    while True:
        X1i = genX1.next()
        X2i = genX2.next()
        yield X1i[0], X2i[0]

"""Definizione rete"""

# Definizione del modello UNET
BACKBONE = 'resnet34'
model = Unet(backbone_name=BACKBONE,
            input_shape=(512,512,3),            #(altezza, larghezza, canali RGB)
            encoder_weights='imagenet',
            encoder_freeze=True,
            decoder_block_type='transpose',
            classes=2,
            activation='sigmoid')

# Definizione algoritmo di ottimizzazione e funzione di loss
model.compile('Adam', loss='binary_crossentropy', metrics=['binary_accuracy'])

"""Allenamento rete"""

# Parametri della rete
n_train_samples = len(X_train) # numero delle immagini di train
n_val_samples = len(X_val)     # numero delle immagini di validation
batch_size = 8
n_epochs = 20

# Checkpoint definition
csv_logger = CSVLogger('./log.out', append=True, separator=';')
earlystopping = EarlyStopping(monitor = 'val_binary_accuracy',verbose = 1, min_delta = 0.01, patience = 2, mode = 'max')
callbacks_list = [csv_logger, earlystopping]

# Train model
results = model.fit_generator(XYaugmentGenerator(X_train,Y_train,seed, batch_size),
                              steps_per_epoch = np.ceil(float(len(X_train))/float(batch_size)),
                              validation_data = val_datagen.flow(X_val,Y_val,batch_size),
                              validation_steps = np.ceil(float(len(X_val))/float(batch_size)),
                              shuffle = True,
                              epochs = n_epochs,
                              callbacks = callbacks_list)

"""testing rete"""

# prendo il path del computer di colab cosi non usiamo la memoria di drive
path = os.getcwd()

# Path
TEST_IMG_path = os.path.join('test', 'images')
TEST_MASK_path = os.path.join('test', 'manual')

# Creare la cartella che conterrà i risultati della rete nel test set
path_results = 'testing_results'
if not os.path.exists(path + '/' + path_results):
  os.mkdir(path + '/' + path_results)

# Scorrere tutte le immagini del test set ed applicare la UNET
test_images = os.listdir(TEST_IMG_path)

performance=np.zeros([len(test_images),3])                                  #variabile per salvare le performance

for n, id_ in tqdm(enumerate(test_images), total=len(test_images)):

    # Load data
    img = imread(TEST_IMG_path+'/'+id_) #[:,:,:IMG_CHANNELS]
    img = resize(img, [IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS])
    img = img_as_ubyte(img)

    # Load manual mask
    mask = imagecodecs.imread(TEST_MASK_path+'/'+id_)
    print(f"mask shape: {mask.shape}")
    dim=mask.shape
    print(dim)
    if len(dim)>2:
      if mask.shape[2]>=1:
         mask = np.sum(mask,2,np.uint8)                     # merge the N layers segmentation in a unique greyscale image

    # Apply CNN for prediction
    img1 = np.reshape(img,(1,512,512,3))
    softmax = model.predict(img1)
    softmax = np.reshape(softmax,(512,512,2))
    softmax = resize(softmax, (450, 600), mode='constant', preserve_range=True)

    mask_auto = softmax[:,:,1]
    mask_auto[mask_auto<0.5]=0
    mask_auto[mask_auto>0.5]=255
    mask_auto = mask_auto.astype(np.uint8)

    # Save mask auto
    path_auto=os.path.join(path,path_results,id_)
    imsave(path_auto,mask_auto)

    #evaluating performances on i-th image and store the info(storing performances on each lesion could help to observe on which ones the CAD do not perform well)
    TP = (mask_auto*mask).sum()
    FP = (mask_auto*~mask).sum()
    FN = (~mask_auto*mask).sum()
    performance[n,0] = TP/(TP+FP)             #precision on i-th image
    performance[n,1] = TP/(TP+FN)             #recall on  i-th image
    performance[n,2] = 2*TP/(2*TP+FP+FN)     #F-SCORE on i-th image

# Stampare una figura di debug, confrontando immagine originale, segmentazione
# manuale e segmentazione effettuata dalla UNET (per l'ultima immagine elaborata)
#path='/content/drive/MyDrive/eim/lab8/'

random_index = randint(0,len(test_images)-1)
print(random_index)

figura=imread(TEST_IMG_path+'/'+test_images[random_index])
maschera_man=imread(TEST_MASK_path+'/'+test_images[random_index])
maschera_auto=imread(path+'testing_results'+'/'+test_images[random_index])

fig = plt.figure(figsize=(30,10))
ax1 = fig.add_subplot(131)
ax1.imshow(figura), ax1.set_title('original image')
ax2 = fig.add_subplot(132)
ax2.imshow(maschera_man, cmap=plt.cm.gray), ax2.set_title('manual')
ax3 = fig.add_subplot(133)
ax3.imshow(maschera_auto, cmap=plt.cm.gray), ax3.set_title('automatic')

#print performances of CADe system
#print(f"\n\nperformances od CADe system across all the samples in the test set(printed as: precision|recall|F-SCORE)\n{perf}")  #uncomment to see performances on esch lesion
mean_perf = np.mean(performance, axis = 0)
print(f"\n\nmean performances of CADe system\nprecision: {mean_perf[0]} | recall: {mean_perf[1]} | F-SCORE: {mean_perf[2]}")